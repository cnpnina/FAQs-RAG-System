import requests
from bs4 import BeautifulSoup
from sentence_transformers import SentenceTransformer
import google.generativeai as genai
import os
import chromadb
from chromadb.utils import embedding_functions
import re
from typing import List
from dotenv import load_dotenv

EMBEDDING_MODEL_NAME = 'sentence-transformers/paraphrase-multilingual-mpnet-base-v2'
GEMINI_LLM_MODEL = 'gemini-2.0-flash-lite'
FAQ_URL = "https://www.tilda.com/faqs/"

class TildaFAQRAG:
    def __init__(self, gemini_api_key):
        genai.configure(api_key=gemini_api_key)
        self.gemini_model = genai.GenerativeModel(GEMINI_LLM_MODEL)
        
        self.embedding_function = embedding_functions.SentenceTransformerEmbeddingFunction(
            model_name=EMBEDDING_MODEL_NAME,
            device='cpu'
        )
        
        self.client = chromadb.Client()
        self.collection_name = "tilda_faqs_collection"
        self.collection = self._create_or_get_collection()

        self.faq_data = []

    def _create_or_get_collection(self):
        print(f"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö/‡∏™‡∏£‡πâ‡∏≤‡∏á Chroma Collection: {self.collection_name}")
        try:
            existing = [c.name for c in self.client.list_collections()]
            if self.collection_name in existing:
                try:
                    self.client.delete_collection(self.collection_name)
                    print("‡∏•‡∏ö collection ‡πÄ‡∏î‡∏¥‡∏°‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÉ‡∏´‡∏°‡πà‡πÅ‡∏ö‡∏ö‡∏™‡∏∞‡∏≠‡∏≤‡∏î")
                except Exception:
                    try:
                        col = self.client.get_collection(self.collection_name)
                        if hasattr(col, "delete"):
                            col.delete()
                    except Exception:
                        pass

            # ‡∏™‡∏£‡πâ‡∏≤‡∏á collection ‡πÉ‡∏´‡∏°‡πà
            collection = self.client.create_collection(
                name=self.collection_name,
                embedding_function=self.embedding_function
            )
            print("Collection ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÉ‡∏´‡∏°‡πà‡πÅ‡∏•‡πâ‡∏ß")
            return collection

        except Exception as e:
            print(f"‚ö†Ô∏è ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏Ç‡∏ì‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á/‡∏î‡∏∂‡∏á collection: {e}")
            print("‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏™‡∏£‡πâ‡∏≤‡∏á fallback collection (‡πÑ‡∏°‡πà‡∏°‡∏µ embedding_function)...")
            try:
                collection = self.client.create_collection(name=self.collection_name)
                print("‡∏™‡∏£‡πâ‡∏≤‡∏á fallback collection ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
                return collection
            except Exception as e2:
                print(f"‚ùå ‡∏™‡∏£‡πâ‡∏≤‡∏á fallback collection ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {e2}")
                raise

    def _get_lang(self, text):
        thai_chars_range = range(0x0E00, 0x0E7F)
        for char in text[:20]:
            if ord(char) in thai_chars_range:
                return 'THAI'
        return 'ENGLISH'

    # ---------- ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏£‡∏ß‡∏à‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°/‡∏î‡∏∂‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö ----------
    def _is_question_candidate(self, text: str) -> bool:
        if not text:
            return False
        text = text.strip()
        if len(text) < 3 or len(text) > 300:
            return False
        if text.endswith('?'):
            return True
        # ‡∏ñ‡πâ‡∏≤‡∏Ç‡∏∂‡πâ‡∏ô‡∏ï‡πâ‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©‡∏ó‡∏µ‡πà‡∏û‡∏ö‡∏ö‡πà‡∏≠‡∏¢
        start = text.lower().split()[0] if text.split() else ""
        question_words = {'what','how','is','are','can','do','where','when','why','which','does','will','should'}
        if start in question_words:
            return True
        # ‡∏Å‡∏£‡∏ì‡∏µ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏Ñ‡∏≤‡∏î‡πÄ‡∏õ‡πá‡∏ô question (‡πÄ‡∏ä‡πà‡∏ô 'Can I', 'Do you')
        if re.match(r'^(can|do|is|are|what|how|where|when|why|which)\b', text.strip(), re.I):
            return True
        return False

    def _extract_linear_faqs(self, container) -> List[dict]:
        nodes = []
        # ‡πÄ‡∏Å‡πá‡∏ö only tags that contain visible text (to reduce noise)
        for el in container.find_all(recursive=True):
            txt = el.get_text(separator=" ", strip=True)
            if txt:
                nodes.append((el, txt))

        faqs = []
        idx = 0
        node_len = len(nodes)
        while idx < node_len:
            el, txt = nodes[idx]
            if self._is_question_candidate(txt):
                # found question - now gather answer from subsequent nodes until next question
                q_text = txt.strip()
                answer_parts = []
                j = idx + 1
                # special-case: if element has aria-controls -> find panel by id
                aria = el.attrs.get('aria-controls') or el.attrs.get('data-target') or el.attrs.get('data-controls')
                if aria:
                    panel = container.find(id=aria) or container.find(attrs={"data-id": aria})
                    if panel:
                        panel_text = panel.get_text(separator=" ", strip=True)
                        if panel_text:
                            answer_parts.append(panel_text)

                # else linear gather
                while j < node_len:
                    next_el, next_txt = nodes[j]
                    if self._is_question_candidate(next_txt):
                        break
                    # skip if text is duplicate of question or too short
                    if next_txt and len(next_txt) > 10:
                        answer_parts.append(next_txt)
                    j += 1

                a_text = " ".join(answer_parts).strip()
                if a_text:
                    faqs.append({
                        "question": q_text,
                        "answer": a_text
                    })
                idx = j
            else:
                idx += 1

        return faqs

    def scrape_faq(self):
        """‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• FAQ ‡∏à‡∏≤‡∏Å‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå Tilda ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ heuristic ‡∏ó‡∏µ‡πà‡∏ó‡∏ô‡∏ó‡∏≤‡∏ô‡∏Ç‡∏∂‡πâ‡∏ô"""
        print(f"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• FAQ ‡∏à‡∏≤‡∏Å {FAQ_URL}...")
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        }
        try:
            response = requests.get(FAQ_URL, headers=headers, timeout=20)
            response.raise_for_status()
            soup = BeautifulSoup(response.content, 'html.parser')

            # ‡∏´‡∏≤ FAQ section
            faq_section = soup.find('div', class_=lambda c: c and 't453' in c) \
                          or soup.find('section', class_=lambda c: c and 'faq' in c.lower()) \
                          or soup.find('div', id=lambda i: i and 'faq' in i.lower())

            if not faq_section:
                print("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏ö‡∏•‡πá‡∏≠‡∏Å FAQ ‡∏´‡∏•‡∏±‡∏Å (t453) ‡∏à‡∏∞‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏à‡∏≤‡∏Å body ‡πÅ‡∏ó‡∏ô")
                faq_section = soup.find('body')

            # ‡πÉ‡∏ä‡πâ linear extractor
            extracted = self._extract_linear_faqs(faq_section)

            # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏û‡∏≠‡πÉ‡∏à‡∏ú‡∏• ‡πÉ‡∏´‡πâ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏´‡∏≤‡πÅ‡∏ö‡∏ö accordion items ‡πÄ‡∏â‡∏û‡∏≤‡∏∞ (fallback)
            if not extracted:
                # ‡∏´‡∏≤ elements ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏•‡∏≤‡∏™‡πÄ‡∏õ‡πá‡∏ô accordion / item ‡πÅ‡∏•‡πâ‡∏ß‡∏•‡∏≠‡∏á parse
                candidates = faq_section.find_all(class_=lambda c: c and any(k in c.lower() for k in ['accordion', 'faq', 't453__item', 'toggle', 'js-accordion']))
                for cand in candidates:
                    # ‡∏´‡∏≤‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡πÅ‡∏•‡∏∞‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á
                    q = cand.find(lambda tag: tag.name in ['h2','h3','button','summary','a'] or (tag.get('class') and any('question' in cl for cl in tag.get('class'))))
                    a = cand.find(lambda tag: tag.name in ['div','p','section'] or (tag.get('class') and any(k in cl for k in ['answer','content','body','panel','descr'] for cl in tag.get('class'))))
                    qtxt = q.get_text(separator=" ", strip=True) if q else None
                    atxt = a.get_text(separator=" ", strip=True) if a else None
                    if qtxt and atxt and len(atxt) > 10 and self._is_question_candidate(qtxt):
                        extracted.append({"question": qtxt, "answer": atxt})

            # Final fallback: ‡∏´‡∏≤‡∏Å‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏û‡∏ö ‡πÉ‡∏´‡πâ‡∏•‡∏≠‡∏á‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ó‡∏∏‡∏Å element ‡∏ó‡∏µ‡πà‡∏°‡∏µ '?' ‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏ö‡∏Ñ‡∏π‡πà‡∏Å‡∏±‡∏ö next sibling paragraph
            if not extracted:
                for tag in faq_section.find_all(text=re.compile(r'\?')):
                    parent = tag.parent
                    qtxt = parent.get_text(separator=" ", strip=True)
                    if not self._is_question_candidate(qtxt):
                        continue
                    # next sibling paragraphs
                    sib = parent.find_next_sibling()
                    atxt = ""
                    while sib and len(atxt) < 20:
                        atxt = sib.get_text(separator=" ", strip=True)
                        if atxt:
                            break
                        sib = sib.find_next_sibling()
                    if atxt:
                        extracted.append({"question": qtxt, "answer": atxt})

            # normalize into faq_data with categories (best-effort)
            self.faq_data = []
            for i, item in enumerate(extracted):
                # best-effort try to determine category by nearest heading above element
                q = item['question'].strip()
                a = item['answer'].strip()
                category = "General"
                # Attempt to find the nearest heading in the page (search backward)
                # We do a simple heuristic: search for last <h2>/<h3> text before the question text in HTML
                # (This is a best-effort and may not always be perfect)
                self.faq_data.append({
                    'id': f"faq_{i+1}",
                    'category': category,
                    'question': q,
                    'answer': a,
                    'combined': f"Category: {category}\nQuestion: {q}\nAnswer: {a}"
                })

            if not self.faq_data:
                print("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á FAQ ‡∏ó‡∏µ‡πà‡∏Ñ‡∏≤‡∏î‡πÑ‡∏ß‡πâ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÇ‡∏Ñ‡πâ‡∏î Web Scraping")
                # ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏£‡∏≠‡∏á
                self.faq_data = [{
                    'id': 'faq_1',
                    'category': 'Company',
                    'question': 'Is Tilda an Indian Company?',
                    'answer': 'Tilda is a British company that was founded by a Ugandan family who migrated to the UK back in the 70s.',
                    'combined': 'Category: Company\nQuestion: Is Tilda an Indian Company?\nAnswer: Tilda is a British company.'
                }]
                print("üí° ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• FAQ ‡∏™‡∏≥‡∏£‡∏≠‡∏á‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å Scrape ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")

            print(f"‚úÖ ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: ‡∏û‡∏ö {len(self.faq_data)} ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°")
            # ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏£‡∏∏‡∏õ‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà (best-effort)
            categories_count = {}
            for faq in self.faq_data:
                categories_count[faq['category']] = categories_count.get(faq['category'], 0) + 1
            print("‡πÅ‡∏ö‡πà‡∏á‡∏ï‡∏≤‡∏°‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà :")
            for cat, cnt in categories_count.items():
                print(f"  - {cat}: {cnt} ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°")

            # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà ChromaDB
            self.add_faqs_to_chroma()
            return self.faq_data

        except requests.exceptions.RequestException as e:
            print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠: {e}")
            return []
        except Exception as e:
            print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•/‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• HTML: {e}")
            return []

    def add_faqs_to_chroma(self):
        if not self.faq_data:
            print("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• FAQ ‡πÉ‡∏´‡πâ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà ChromaDB")
            return

        print("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• FAQ ‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà ChromaDB...")
        documents = [faq['combined'] for faq in self.faq_data]
        metadatas = [{'category': faq['category'], 'question': faq['question'], 'answer': faq['answer']} for faq in self.faq_data]
        ids = [faq['id'] for faq in self.faq_data]

        # add to collection (collection ‡∏ñ‡∏π‡∏Å‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÉ‡∏´‡∏°‡πà‡∏ï‡∏≠‡∏ô init ‡πÅ‡∏•‡πâ‡∏ß)
        try:
            self.collection.add(documents=documents, metadatas=metadatas, ids=ids)
            print(f"‚úÖ ‡πÄ‡∏û‡∏¥‡πà‡∏° {len(self.faq_data)} ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà ChromaDB ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
        except Exception as e:
            print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà ChromaDB: {e}")

    def retrieve_relevant_faqs(self, query, top_k=3):
        results = self.collection.query(query_texts=[query], n_results=top_k)
        relevant_faqs = []
        if results and results.get('ids') and results.get('distances'):
            for i in range(len(results['ids'][0])):
                distance = results['distances'][0][i]
                metadata = results['metadatas'][0][i]
                document = results['documents'][0][i]
                relevant_faqs.append({
                    'context': document,
                    'distance': distance,
                    'category': metadata.get('category'),
                    'question': metadata.get('question'),
                    'answer': metadata.get('answer')
                })
        return relevant_faqs

    def generate_answer(self, query, relevant_faqs):
        context = "\n\n".join([
            f"FAQ {i+1} (Category: {faq['category']}):\nQuestion: {faq['question']}\nAnswer: {faq['answer']}\n(Distance: {faq['distance']:.2f})"
            for i, faq in enumerate(relevant_faqs)
        ])
        query_lang = self._get_lang(query)
        if query_lang == 'THAI':
            lang_instruction = "‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"
            no_info_msg = "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏Ñ‡πà‡∏∞ ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö FAQ"
        else:
            lang_instruction = "Answer entirely in English"
            no_info_msg = "I apologize, but I couldn't find relevant information in the FAQ."

        prompt = f"""
You are an AI assistant that answers questions about Tilda company products (premium Basmati rice).

Relevant FAQ data from the website:
{context}

Customer Question: {query}

Please generate the answer based on the following rules:
1. Use the provided FAQ data as the primary source.
2. Be friendly, clear, and concise.
3. **{lang_instruction}**
4. If the FAQ data does not contain the answer, say: "{no_info_msg}"
5. Do not mention that the information came from the FAQ or include the distance score.

Answer:
"""
        try:
            response = self.gemini_model.generate_content(prompt)
            text = getattr(response, "text", None) or getattr(response, "result", None) or str(response)
            return text
        except Exception as e:
            return f"An error occurred while generating the answer: {e}\nPlease try again or contact our team."

    def answer_question(self, query):
        print(f"\n{'='*70}")
        print(f"üí¨ ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: {query}")
        print(f"{'='*70}")

        relevant_faqs = self.retrieve_relevant_faqs(query, top_k=3)

        if not relevant_faqs:
            return "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏Ñ‡πà‡∏∞ ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö FAQ"
        
        """""""""""
        print("\nüìö FAQ ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á (‡∏î‡∏∂‡∏á‡∏à‡∏≤‡∏Å ChromaDB):")
        for i, faq in enumerate(relevant_faqs, 1):
            print(f" {i}. [{faq['category']}] {faq['question']}")
            print(f" Distance (L2): {faq['distance']:.2f} (‡∏Ñ‡πà‡∏≤‡∏ï‡πà‡∏≥‡∏Ñ‡∏∑‡∏≠‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏°‡∏≤‡∏Å)")
        """""

        print("\n‚è≥ generate answer...")
        answer = self.generate_answer(query, relevant_faqs)

        print(f"\n‚ú® ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö:")
        print(f"{'-'*70}")
        print(answer)
        print(f"{'-'*70}\n")

        return answer



# ‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
if __name__ == "__main__":
    
    load_dotenv()
    GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

    if not GEMINI_API_KEY:
        print("‚ö†Ô∏è ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Environment Variable ‡∏ä‡∏∑‡πà‡∏≠ GEMINI_API_KEY ‡∏Å‡πà‡∏≠‡∏ô‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")

    print("üöÄ Welcome to the Tilda chatbot system. If you have any questions, please feel free to ask!")
    print("=" * 70)

    try:
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏∞‡∏ö‡∏ö RAG
        rag = TildaFAQRAG(GEMINI_API_KEY)

        # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• FAQ ‡πÅ‡∏•‡∏∞‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏Ç‡πâ‡∏≤ ChromaDB
        rag.scrape_faq()

        if rag.collection.count() == 0:
            print("‚ö†Ô∏è ‡∏Ñ‡∏≥‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô: ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô Vector DB ‡∏´‡∏•‡∏±‡∏á‡∏Å‡∏≤‡∏£ scrape. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡πà‡∏≠‡∏ô‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")
        else:
            print("\n‚úÖ ‡∏£‡∏∞‡∏ö‡∏ö‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô! ‡∏õ‡πâ‡∏≠‡∏ô‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏î‡∏™‡∏≠‡∏ö (‡∏û‡∏¥‡∏°‡∏û‡πå 'exit' ‡∏´‡∏£‡∏∑‡∏≠ 'quit' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏£‡∏∞‡∏ö‡∏ö)\n")

        # Interactive loop: ‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏à‡∏≤‡∏Å user ‡∏ú‡πà‡∏≤‡∏ô input()
        while True:
            try:
                user_q = input("‡∏ñ‡∏≤‡∏°‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå Tilda > ").strip()
            except (KeyboardInterrupt, EOFError):
                print("\n‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏£‡∏∞‡∏ö‡∏ö‡πÇ‡∏î‡∏¢‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ")
                break

            if not user_q:
                continue
            if user_q.lower() in ("exit", "quit", "q"):
                print("‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏£‡∏∞‡∏ö‡∏ö... ‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏µ‡πà‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏£‡∏∞‡∏ö‡∏ö Tilda chatbot system ‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤!")
                break

            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô ChromaDB ‡∏Å‡πà‡∏≠‡∏ô‡∏ï‡∏≠‡∏ö
            if rag.collection.count() == 0:
                print("‡∏Ç‡∏≠‡πÇ‡∏ó‡∏©‡∏Ñ‡πà‡∏∞ ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏∂‡∏á‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÑ‡∏î‡πâ")
                continue

            # ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°
            try:
                rag.answer_question(user_q)
            except Exception as e:
                print(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: {e}")
                print("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏•‡∏≠‡∏á‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á ‡∏´‡∏£‡∏∑‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö Gemini/ChromaDB")

    except Exception as e:
        print(f"\nFATAL ERROR: {e}")

